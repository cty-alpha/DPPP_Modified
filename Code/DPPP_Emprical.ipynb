{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import random\n",
    "from scipy import stats\n",
    "plt.rcParams['font.family'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_path = r\"上证50月度因子+收益+权重数据2005-2024.csv\"\n",
    "df = pd.read_csv(file_path,parse_dates=['date'])\n",
    "df['weight'] = df['weight']/100\n",
    "column = df.columns.tolist()[7:]\n",
    "target_rows = 50\n",
    "\n",
    "def compress_weights(weights, max_weight=0.03):\n",
    "    return np.minimum(weights, max_weight)\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    return weights / weights.sum()\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)  # 减去最大值防止溢出\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "def annualized_return(returns):\n",
    "    total_return = np.prod(1 + returns) - 1\n",
    "    annualized_return = (1 + total_return) ** (12 / len(returns)) - 1\n",
    "    return annualized_return\n",
    "\n",
    "def annualized_volatility(returns):\n",
    "    return np.std(returns) * np.sqrt(12)\n",
    "\n",
    "def sharpe_ratio(returns, risk_free_rate=0.02):\n",
    "    return (annualized_return(returns) - risk_free_rate) / annualized_volatility(returns)\n",
    "\n",
    "def calmar_ratio(returns):\n",
    "    annual_return = (np.prod(1 + returns) ** (12 / len(returns))) - 1  # 假设是月度收益率\n",
    "    cumulative = np.cumprod(1 + returns)  \n",
    "    peak = np.maximum.accumulate(cumulative)  \n",
    "    drawdown = (peak - cumulative) / peak  \n",
    "    max_drawdown = np.max(drawdown) \n",
    "    return annual_return / max_drawdown if max_drawdown > 0 else np.nan\n",
    "\n",
    "def pad_to_rows(array, target_rows):\n",
    "    current_rows, cols = array.shape\n",
    "    if current_rows < target_rows:\n",
    "        pad_width = [(0, target_rows - current_rows), (0, 0)]\n",
    "        padded_array = np.pad(array, pad_width, mode='constant', constant_values=0)\n",
    "    else:\n",
    "        padded_array = array\n",
    "    return padded_array\n",
    "\n",
    "def pad_to_length(array, target_rows):\n",
    "    current_length = array.shape[0]\n",
    "    if current_length < target_rows:\n",
    "        pad_width = (0, target_rows - current_length)\n",
    "        padded_array = np.pad(array, pad_width, mode='constant', constant_values=0)\n",
    "    else:\n",
    "        padded_array = array\n",
    "    return padded_array\n",
    "\n",
    "initial_train_end = '2020-12-31'  # 初始训练集结束时间\n",
    "df_performance = pd.DataFrame()\n",
    "net_value_dfs = []\n",
    "\n",
    "# gamma_value = 50\n",
    "learning_rate = 1e-4\n",
    "epochs = 50\n",
    "batch_size = 5  \n",
    "lambda_value = 0.005\n",
    "input_size = df.shape[1] - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_train = df[df['date'] <= initial_train_end].copy()\n",
    "\n",
    "for gamma_value in [10,20,30,40,50][2:3]:\n",
    "    df_result = pd.DataFrame()\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(MLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, 128)\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.fc3 = nn.Linear(64, 1)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        def forward(self, x):\n",
    "            out1 = self.relu(self.fc1(x))\n",
    "            out2 = self.relu(self.fc2(out1))\n",
    "            out3 = self.fc3(out2)\n",
    "            out3 = self.sigmoid(out3)\n",
    "            return out3\n",
    "        \n",
    "    class MLP_Contrast(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(MLP_Contrast, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, 128)\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.fc3 = nn.Linear(64, 1)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        def forward(self, x):\n",
    "            out1 = self.relu(self.fc1(x))\n",
    "            out2 = self.relu(self.fc2(out1))\n",
    "            out3 = self.fc3(out2)\n",
    "            out3 = self.sigmoid(out3)\n",
    "            return out3\n",
    "        \n",
    "    def overall_utility(model, X, y, gamma=gamma_value):\n",
    "        all_portfolio_returns = []  # 存储所有截面加权收益率\n",
    "        for idx in range(len(X)):\n",
    "            X_batch, y_batch = X[idx], y[idx]\n",
    "            raw_weights = model(X_batch).squeeze()\n",
    "            weights = torch.softmax(raw_weights, dim=0)  # 权重归一化\n",
    "            \n",
    "            # weights = raw_weights/raw_weights.sum()\n",
    "            # # 论文原文方法\n",
    "            # weights = (raw_weights-raw_weights.mean())/raw_weights.std()/target_rows\n",
    "\n",
    "            portfolio_return = torch.sum(weights * y_batch)\n",
    "            utility_section = ((1+portfolio_return)**(1-gamma))/(1-gamma)\n",
    "            lamda = 0\n",
    "            squared_sum = lamda*torch.sum(weights**2)\n",
    "            utility_section = -utility_section+squared_sum\n",
    "            all_portfolio_returns.append(utility_section)\n",
    "            \n",
    "        utility = sum(all_portfolio_returns)\n",
    "        return utility  # 负效用用于优化\n",
    "\n",
    "    def overall_utility_contrast(model, X, y, gamma=gamma_value):\n",
    "        all_portfolio_returns = []  # 存储所有截面加权收益率\n",
    "        for idx in range(len(X)):\n",
    "            X_batch, y_batch = X[idx], y[idx]\n",
    "            raw_weights = model(X_batch).squeeze()\n",
    "            weights = torch.softmax(raw_weights, dim=0)  # 权重归一化\n",
    "            \n",
    "            # weights = raw_weights/raw_weights.sum()\n",
    "            # # 论文原文方法\n",
    "            # weights = (raw_weights-raw_weights.mean())/raw_weights.std()/target_rows\n",
    "\n",
    "            portfolio_return = torch.sum(weights * y_batch)\n",
    "            utility_section = ((1+portfolio_return)**(1-gamma))/(1-gamma)\n",
    "            lamda = lambda_value\n",
    "            squared_sum = lamda*torch.sum(weights**2)\n",
    "            utility_section = -utility_section+squared_sum\n",
    "            all_portfolio_returns.append(utility_section)\n",
    "            \n",
    "        utility = sum(all_portfolio_returns)\n",
    "        return utility\n",
    "    \n",
    "    #============================策略训练=======================================\n",
    "    model = MLP(input_size)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    test_set = df[(df['date'] > initial_train_end) & (df['date'] <= '2025')].copy()\n",
    "    test_groups = list(test_set.groupby('date'))\n",
    "    train_groups = list(current_train.groupby('date'))\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_train_loss = 0\n",
    "        epoch_test_loss = 0\n",
    "        random.shuffle(train_groups)\n",
    "        for batch_idx in range(0, len(train_groups)-batch_size, batch_size):\n",
    "            # 训练集上第N个batch截取（6个截面）\n",
    "            batch_groups = train_groups[batch_idx:batch_idx + batch_size]\n",
    "            batch_features = []\n",
    "            batch_labels = []\n",
    "            for _, group_df in batch_groups:  #对batch上的每一个截面循环处理\n",
    "                features = group_df[column].values\n",
    "                features = pad_to_rows(features, target_rows)\n",
    "                labels = group_df['ret_o2c_next_month'].values\n",
    "                labels = pad_to_length(labels, target_rows)\n",
    "                batch_features.append(features)\n",
    "                batch_labels.append(labels)\n",
    "\n",
    "            features_tensor = torch.tensor(batch_features, dtype=torch.float32)\n",
    "            labels_tensor = torch.tensor(batch_labels, dtype=torch.float32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = overall_utility(model, features_tensor, labels_tensor, gamma=gamma_value)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        # 计算测试集损失\n",
    "        with torch.no_grad():\n",
    "            for _, group_df in test_groups:\n",
    "                test_features = torch.tensor(\n",
    "                    group_df[column].values,dtype=torch.float32).unsqueeze(0)\n",
    "                test_labels = torch.tensor(group_df['ret_o2c_next_month'].values, dtype=torch.float32).unsqueeze(0)\n",
    "                test_loss = overall_utility(model, test_features, test_labels, gamma=gamma_value)\n",
    "                epoch_test_loss += test_loss.item()\n",
    "        \n",
    "        # 记录损失\n",
    "        train_losses.append(epoch_train_loss / len(train_groups ))\n",
    "        test_losses.append(epoch_test_loss / len(test_groups))\n",
    "        print(f'Gamma={gamma_value}: Strategy: Epoch {epoch + 1}, Train Loss: {train_losses[-1]:.8f}, Test Loss: {test_losses[-1]:.8f}')\n",
    "    print('='*30)\n",
    "    #============================对照组训练=======================================\n",
    "    model_contrast = MLP_Contrast(input_size)\n",
    "    optimizer_contrast = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    test_set = df[(df['date'] > initial_train_end) & (df['date'] <= '2025')].copy()\n",
    "    test_groups = list(test_set.groupby('date'))\n",
    "    train_groups = list(current_train.groupby('date'))\n",
    "    train_losses_contrast = []\n",
    "    test_losses_contrast = []\n",
    "    batch_size_contrast = 5\n",
    "    for epoch in range(5):\n",
    "        epoch_train_loss_contrast = 0\n",
    "        epoch_test_loss_contrast = 0\n",
    "        random.shuffle(train_groups)\n",
    "        for batch_idx in range(0, len(train_groups)-batch_size_contrast, batch_size_contrast):\n",
    "        # for batch_idx in range(0, 1):\n",
    "            batch_groups_contrast = train_groups[batch_idx:batch_idx + batch_size_contrast]\n",
    "            batch_features_contrast = []\n",
    "            batch_labels_contrast = []\n",
    "            for _, group_df in batch_groups_contrast:  #对batch上的每一个截面循环处理\n",
    "                features = group_df[column].values\n",
    "                features = pad_to_rows(features, target_rows)\n",
    "                labels = group_df['ret_o2c_next_month'].values\n",
    "                labels = pad_to_length(labels, target_rows)\n",
    "                batch_features_contrast.append(features)\n",
    "                batch_labels_contrast.append(labels)\n",
    "\n",
    "            features_tensor_contrast = torch.tensor(batch_features_contrast, dtype=torch.float32)\n",
    "            labels_tensor_contrast = torch.tensor(batch_labels_contrast, dtype=torch.float32)\n",
    "\n",
    "            optimizer_contrast.zero_grad()\n",
    "            loss_contrast = overall_utility_contrast(\n",
    "                model_contrast, features_tensor_contrast, \n",
    "                labels_tensor_contrast, gamma=gamma_value)\n",
    "            loss_contrast.backward()\n",
    "            optimizer_contrast.step()\n",
    "            epoch_train_loss_contrast += loss_contrast.item()\n",
    "        \n",
    "        # 计算测试集损失\n",
    "        with torch.no_grad():\n",
    "            for _, group_df in test_groups:\n",
    "                test_features_contrast = torch.tensor(\n",
    "                    group_df[column].values,dtype=torch.float32).unsqueeze(0)\n",
    "                test_labels_contrast = torch.tensor(group_df['ret_o2c_next_month'].values, dtype=torch.float32).unsqueeze(0)\n",
    "                test_loss_contrast = overall_utility_contrast(\n",
    "                    model_contrast, test_features_contrast, \n",
    "                    test_labels_contrast, gamma=gamma_value)\n",
    "                epoch_test_loss_contrast += test_loss_contrast.item()\n",
    "        \n",
    "        # 记录损失\n",
    "        train_losses_contrast.append(epoch_train_loss_contrast / len(train_groups ))\n",
    "        test_losses_contrast.append(epoch_test_loss_contrast / len(test_groups))\n",
    "        print(f'Gamma={gamma_value}: Contrast: Epoch {epoch + 1}, Train Loss: {train_losses_contrast[-1]:.8f}, Test Loss: {test_losses_contrast[-1]:.8f}')\n",
    "    print('='*30)\n",
    "    #============================Training and Prediction Losses============================\n",
    "    # 在主坐标轴上绘制 loss_train_list 的数据\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Times')\n",
    "    ax1.set_ylabel('Training Loss', color=color)\n",
    "    line1 = ax1.plot(train_losses, color=color, label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # 在副坐标轴上绘制 loss_pred_list 的数据\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Prediction Loss', color=color)\n",
    "    line2 = ax2.plot(test_losses, color=color, label='Prediction Loss')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper left')\n",
    "    plt.title(f'Gamma={gamma_value}-Training and Prediction Losses')\n",
    "    if not os.path.exists('DPPP_daily_result'):\n",
    "        os.makedirs('DPPP_daily_result')\n",
    "    save_path2 = os.path.join('DPPP_daily_result', f'Gamma={gamma_value}-Training and Prediction Losses.png')\n",
    "    plt.savefig(save_path2)\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "    #===============================================================================\n",
    "\n",
    "    X_pred = test_set[column].values\n",
    "    X_pred = torch.tensor(X_pred, dtype=torch.float32)\n",
    "    with torch.no_grad():  \n",
    "        raw_weights_pred = model(X_pred)  # 预测原始权重\n",
    "    weights_pred = raw_weights_pred\n",
    "    weights_pred_numpy = weights_pred.numpy().flatten()\n",
    "    with torch.no_grad():  \n",
    "        raw_weights_pred_contrast = model_contrast(X_pred)  # 预测原始权重\n",
    "    weights_pred_contrast = raw_weights_pred_contrast\n",
    "    weights_pred_numpy_contrast = weights_pred_contrast.numpy().flatten()\n",
    "\n",
    "    df_pred =test_set.copy()\n",
    "    df_pred.loc[:, 'predicted_weights'] = weights_pred_numpy.astype(np.float32)\n",
    "    df_pred.loc[:, 'predicted_weights_contrast'] = weights_pred_numpy_contrast.astype(np.float32)\n",
    "    # #论文原文方法\n",
    "    # df_pred['predicted_weights_contrast'] = df_pred['predicted_weights_contrast']+df_pred['weight']\n",
    "    df_pred = df_pred[['code', 'date', 'name', 'weight', \n",
    "                        'ret_o2c_next_month', 'predicted_weights',\n",
    "                        'predicted_weights_contrast']]\n",
    "\n",
    "    df_pred['predicted_weights'] = df_pred.groupby(\n",
    "        'date')['predicted_weights'].transform(softmax)\n",
    "    df_pred['predicted_weights_contrast'] = df_pred.groupby(\n",
    "        'date')['predicted_weights_contrast'].transform(softmax)\n",
    "    df_pred['predicted_weights_contrast'] = df_pred.groupby(\n",
    "        'date')['predicted_weights_contrast'].transform(compress_weights)\n",
    "    df_result = pd.concat([df_result,df_pred],axis=0)\n",
    "\n",
    "    group_num = 10\n",
    "    df_pred['group'] = pd.qcut(\n",
    "        df_pred['predicted_weights'],\n",
    "        q=group_num,  \n",
    "        labels=range(1,group_num+1),\n",
    "        duplicates='drop'\n",
    "    )\n",
    "    df_pred['group_contrast'] = pd.qcut(\n",
    "        df_pred['predicted_weights_contrast'],\n",
    "        q=group_num,  \n",
    "        labels=range(1,group_num+1),\n",
    "        duplicates='drop'\n",
    "    )\n",
    "    group_stats = df_pred.groupby('group').agg({\n",
    "        'predicted_weights': 'mean',          # 预测因子均值（用于分组排序）\n",
    "        'ret_o2c_next_month': ['mean', 'std', 'count']  # 实际收益率统计量\n",
    "    }).reset_index()\n",
    "    group_stats_contrast = df_pred.groupby('group_contrast').agg({\n",
    "        'predicted_weights_contrast': 'mean',          # 预测因子均值（用于分组排序）\n",
    "        'ret_o2c_next_month': ['mean', 'std', 'count']  # 实际收益率统计量\n",
    "    }).reset_index()\n",
    "\n",
    "    # 重命名列\n",
    "    group_stats.columns = ['group', 'predicted_weights_mean', 'ret_mean', 'ret_std', 'n_samples']\n",
    "    group_stats_contrast.columns = ['group_contrast', 'predicted_weights_mean', 'ret_mean', 'ret_std', 'n_samples']\n",
    "    # ==================== 策略组分层检验可视化 ====================\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    color_bar = \"#1f77b4\" \n",
    "    ax1.bar(\n",
    "        group_stats[\"group\"], \n",
    "        group_stats[\"ret_mean\"], \n",
    "        color=color_bar, \n",
    "        alpha=0.7, \n",
    "        width=0.6, \n",
    "        label=\"收益率均值\"\n",
    "    )\n",
    "    ax1.set_xlabel(f'分组 (1=最低预测, {group_num}=最高预测)', fontsize=12)\n",
    "    ax1.set_ylabel(\"收益率均值 (ret_mean)\", fontsize=12, color=color_bar)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color_bar)\n",
    "    ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color_line = \"#d62728\" \n",
    "    ax2.plot(\n",
    "        group_stats[\"group\"], \n",
    "        group_stats[\"ret_std\"], \n",
    "        color=color_line, \n",
    "        marker=\"o\", \n",
    "        linestyle=\"--\", \n",
    "        linewidth=2, \n",
    "        markersize=8, \n",
    "        label=\"波动率 (ret_std)\"\n",
    "    )\n",
    "    ax2.set_ylabel(\"波动率 (标准差)\", fontsize=12, color=color_line)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=color_line)\n",
    "    ax2.grid(axis=\"y\", linestyle=\":\", alpha=0.5)  \n",
    "\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(\n",
    "        lines1 + lines2, \n",
    "        labels1 + labels2, \n",
    "        loc=\"upper left\", \n",
    "        fontsize=10, \n",
    "        framealpha=0.9\n",
    "    )\n",
    "    plt.title(\"Strategy-分层检验：收益率均值与波动率\", fontsize=14, pad=20)\n",
    "    plt.xticks(group_stats[\"group\"])  \n",
    "    fig.tight_layout()\n",
    "    save_path = os.path.join('DPPP_daily_result', f'Strategy-Gamma={gamma_value}-分层检验.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    #===================================对照组分层检验==================================\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    color_bar = \"#1f77b4\" \n",
    "    ax1.bar(\n",
    "        group_stats_contrast[\"group_contrast\"], \n",
    "        group_stats_contrast[\"ret_mean\"], \n",
    "        color=color_bar, \n",
    "        alpha=0.7, \n",
    "        width=0.6, \n",
    "        label=\"收益率均值\"\n",
    "    )\n",
    "    ax1.set_xlabel(f'分组 (1=最低预测, {group_num}=最高预测)', fontsize=12)\n",
    "    ax1.set_ylabel(\"收益率均值 (ret_mean)\", fontsize=12, color=color_bar)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color_bar)\n",
    "    ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color_line = \"#d62728\" \n",
    "    ax2.plot(\n",
    "        group_stats_contrast[\"group_contrast\"], \n",
    "        group_stats_contrast[\"ret_std\"], \n",
    "        color=color_line, \n",
    "        marker=\"o\", \n",
    "        linestyle=\"--\", \n",
    "        linewidth=2, \n",
    "        markersize=8, \n",
    "        label=\"波动率 (ret_std)\"\n",
    "    )\n",
    "    ax2.set_ylabel(\"波动率 (标准差)\", fontsize=12, color=color_line)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=color_line)\n",
    "    ax2.grid(axis=\"y\", linestyle=\":\", alpha=0.5)  \n",
    "\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(\n",
    "        lines1 + lines2, \n",
    "        labels1 + labels2, \n",
    "        loc=\"upper left\", \n",
    "        fontsize=10, \n",
    "        framealpha=0.9\n",
    "    )\n",
    "    plt.title(\"Contrast-分层检验：收益率均值与波动率\", fontsize=14, pad=20)\n",
    "    plt.xticks(group_stats_contrast[\"group_contrast\"])  # 确保分组标签完整显示\n",
    "    fig.tight_layout()\n",
    "    save_path = os.path.join('DPPP_daily_result', f'Contrast-Gamma={gamma_value}-分层检验.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    df_result['weight_ret'] = df_result['ret_o2c_next_month']*df_result['predicted_weights']\n",
    "    df_result['weight_ret_contrast'] = df_result['ret_o2c_next_month']*df_result['predicted_weights_contrast']\n",
    "    df_result['baseline_ret'] = df_result['ret_o2c_next_month']*df_result['weight']\n",
    "    df_net_value = df_result.groupby('date')[['weight_ret','baseline_ret','weight_ret_contrast']].sum()\n",
    "    df_net_value = df_net_value.reset_index(drop=False)\n",
    "    # df_net_value['premium'] = df_net_value['weight_ret']-df_net_value['baseline_ret']\n",
    "\n",
    "    # 手续费\n",
    "    df_net_value['weight_ret'] = df_net_value['weight_ret']-0.00\n",
    "    df_net_value['net_value'] = (1+df_net_value['weight_ret']).cumprod()\n",
    "    df_net_value['net_value_contrast'] = (1+df_net_value['weight_ret_contrast']).cumprod()\n",
    "    df_net_value['baseline_net_value'] = (1+df_net_value['baseline_ret']).cumprod()\n",
    "    # df_net_value['premium'] = (1+df_net_value['premium']).cumprod()\n",
    "    df_net_value['net_value'] = df_net_value['net_value']/df_net_value['net_value'].iloc[0]\n",
    "    df_net_value['net_value_contrast'] = df_net_value['net_value_contrast']/df_net_value['net_value_contrast'].iloc[0]\n",
    "    df_net_value['baseline_net_value'] = df_net_value['baseline_net_value']/df_net_value['baseline_net_value'].iloc[0]\n",
    "    # df_net_value['premium'] = df_net_value['premium']/df_net_value['premium'].iloc[0]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df_net_value['date'], df_net_value['net_value'], label='DPPP', color='red')\n",
    "    plt.plot(df_net_value['date'], df_net_value['baseline_net_value'], label='Baseline', color='blue')\n",
    "    plt.plot(df_net_value['date'], df_net_value['net_value_contrast'], label='Contrast', color='orange')\n",
    "    plt.title(f'Gamma_value:{gamma_value}-Cumulative Net Value Curve')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Net Value')\n",
    "    # plt.grid(True)\n",
    "    plt.legend()\n",
    "    save_path1 = os.path.join('DPPP_daily_result', f\"Gamma={gamma_value}-Net_Value.png\")\n",
    "    plt.savefig(save_path1)\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "    # 计算投资组合和基准的年化收益、波动率、夏普比率、Calmar比率\n",
    "    df_net_value['weight_ret'] = df_net_value['weight_ret'].fillna(0)  \n",
    "    df_net_value['baseline_ret'] = df_net_value['baseline_ret'].fillna(0)  \n",
    "    df_net_value['weight_ret_contrast'] = df_net_value['weight_ret_contrast'].fillna(0)\n",
    "\n",
    "    # 计算投资组合\n",
    "    df_net_value['weight_ret_utility'] = ((1 + df_net_value['weight_ret'])**(1 - gamma_value)) / (1 - gamma_value)\n",
    "    weight_ret_average_utility = df_net_value['weight_ret_utility'].mean()\n",
    "    weight_ret_annualized_return = annualized_return(df_net_value['weight_ret'].values)\n",
    "    weight_ret_annualized_volatility = annualized_volatility(df_net_value['weight_ret'].values)\n",
    "    weight_ret_sharpe = sharpe_ratio(df_net_value['weight_ret'].values)\n",
    "    df_net_value['weight_ret_cumulative_max'] = df_net_value['net_value'].cummax()\n",
    "    df_net_value['weight_ret_drawdown'] = (df_net_value['weight_ret_cumulative_max'] - df_net_value['net_value'])/df_net_value['weight_ret_cumulative_max']\n",
    "    weight_ret_max_drawdown = df_net_value['weight_ret_drawdown'].max()\n",
    "    weight_ret_calmar = calmar_ratio(df_net_value['weight_ret'].values)\n",
    "    weight_min_weight = df_result['predicted_weights'].min()\n",
    "    weight_max_weight = df_result['predicted_weights'].max()\n",
    "    win_ratio = (df_net_value['weight_ret']>df_net_value['baseline_ret']).mean()\n",
    "\n",
    "    # 计算Contrast\n",
    "    df_net_value['weight_ret_utility_contrast'] = ((1 + df_net_value['weight_ret_contrast'])**(1 - gamma_value)) / (1 - gamma_value)\n",
    "    weight_ret_average_utility_contrast = df_net_value['weight_ret_utility_contrast'].mean()\n",
    "    weight_ret_annualized_return_contrast = annualized_return(df_net_value['weight_ret_contrast'].values)\n",
    "    weight_ret_annualized_volatility_contrast = annualized_volatility(df_net_value['weight_ret_contrast'].values)\n",
    "    weight_ret_sharpe_contrast = sharpe_ratio(df_net_value['weight_ret_contrast'].values)\n",
    "    df_net_value['weight_ret_cumulative_max_contrast'] = df_net_value['net_value_contrast'].cummax()\n",
    "    df_net_value['weight_ret_drawdown_contrast'] = (df_net_value['weight_ret_cumulative_max_contrast'] - df_net_value['net_value_contrast'])/df_net_value['weight_ret_cumulative_max_contrast']\n",
    "    weight_ret_max_drawdown_contrast = df_net_value['weight_ret_drawdown_contrast'].max()\n",
    "    weight_ret_calmar_contrast = calmar_ratio(df_net_value['weight_ret_contrast'].values)\n",
    "    weight_min_weight_contrast = df_result['predicted_weights_contrast'].min()\n",
    "    weight_max_weight_contrast = df_result['predicted_weights_contrast'].max()\n",
    "    win_ratio_contrast = (df_net_value['weight_ret_contrast']>df_net_value['baseline_ret']).mean()\n",
    "\n",
    "    # 计算基准\n",
    "    df_net_value['baseline_ret_utility'] = ((1 + df_net_value['baseline_ret'])**(1 - gamma_value)) / (1 - gamma_value)\n",
    "    baseline_ret_average_utility = df_net_value['baseline_ret_utility'].mean()\n",
    "    baseline_ret_annualized_return = annualized_return(df_net_value['baseline_ret'].values)\n",
    "    baseline_ret_annualized_volatility = annualized_volatility(df_net_value['baseline_ret'].values)\n",
    "    baseline_ret_sharpe = sharpe_ratio(df_net_value['baseline_ret'].values)\n",
    "    df_net_value['baseline_ret_cumulative_max'] = df_net_value['baseline_net_value'].cummax()\n",
    "    df_net_value['baseline_ret_drawdown'] = (df_net_value['baseline_ret_cumulative_max'] - df_net_value['baseline_net_value'])/df_net_value['baseline_ret_cumulative_max']\n",
    "    baseline_ret_max_drawdown = df_net_value['baseline_ret_drawdown'].max()\n",
    "    baseline_ret_calmar = calmar_ratio(df_net_value['baseline_ret'].values)\n",
    "    baseline_min_weight = df_result['weight'].min()\n",
    "    baseline_max_weight = df_result['weight'].max()\n",
    "\n",
    "    #SR,utility-p_value-相对于基准\n",
    "    t_stat_utility, p_value_utility = stats.ttest_ind(df_net_value['weight_ret_utility'], df_net_value['baseline_ret_utility'])\n",
    "    t_stat, p_value = stats.ttest_ind(df_net_value['weight_ret'], df_net_value['baseline_ret'])\n",
    "    #SR,utility-p_value-相对于Contrast\n",
    "    t_stat_utility_contrast, p_value_utility_contrast = stats.ttest_ind(df_net_value['weight_ret_utility'], df_net_value['weight_ret_utility_contrast'])\n",
    "    t_stat_contrast, p_value_contrast = stats.ttest_ind(df_net_value['weight_ret'], df_net_value['weight_ret_contrast'])\n",
    "\n",
    "\n",
    "    performance_name = ['CRRA效用','p_utility[DPPP-VW]','p_utility[DPPP-Contrast]',\n",
    "                        '年化收益','年化波动',\n",
    "                        '最大回撤','Calmar比率',\n",
    "                        '最小权重','最大权重','胜率',\n",
    "                        '夏普比率',\n",
    "                        'p_SR[DPPP-VW]','p_SR[DPPP-Contrast]']\n",
    "\n",
    "    strategy_data = [weight_ret_average_utility,p_value_utility,p_value_utility_contrast,\n",
    "                        weight_ret_annualized_return,\n",
    "                        weight_ret_annualized_volatility,\n",
    "                        weight_ret_max_drawdown,weight_ret_calmar,\n",
    "                        weight_min_weight,weight_max_weight,win_ratio,\n",
    "                        weight_ret_sharpe,\n",
    "                        p_value,p_value_contrast]\n",
    "\n",
    "    contrast_data = [weight_ret_average_utility_contrast,p_value_utility_contrast,np.nan,\n",
    "                        weight_ret_annualized_return_contrast,\n",
    "                        weight_ret_annualized_volatility_contrast,\n",
    "                        weight_ret_max_drawdown_contrast,weight_ret_calmar_contrast,\n",
    "                        weight_min_weight_contrast,weight_max_weight_contrast,win_ratio_contrast,\n",
    "                        weight_ret_sharpe_contrast,\n",
    "                        p_value_contrast,np.nan]\n",
    "\n",
    "    baseline_data = [baseline_ret_average_utility,np.nan,np.nan,\n",
    "                        baseline_ret_annualized_return,\n",
    "                        baseline_ret_annualized_volatility,\n",
    "                        baseline_ret_max_drawdown,baseline_ret_calmar,\n",
    "                        baseline_min_weight,baseline_max_weight,np.nan,\n",
    "                        baseline_ret_sharpe,\n",
    "                        np.nan,np.nan]\n",
    "\n",
    "    performance_results = {\n",
    "            f'业绩指标(γ={gamma_value})':performance_name,\n",
    "            f'VW':baseline_data,\n",
    "            f'Contrast(γ={gamma_value})':contrast_data,\n",
    "            f'Strategy(γ={gamma_value})':strategy_data\n",
    "    }\n",
    "\n",
    "    df_results = pd.DataFrame(performance_results)\n",
    "    df_performance = pd.concat([df_performance,df_results],axis=1)\n",
    "\n",
    "    df_net_value = df_net_value.rename(columns={'net_value': f'γ={gamma_value}'})\n",
    "    net_value_dfs.append(df_net_value[['date', f'γ={gamma_value}']])\n",
    "\n",
    "# 打印表格\n",
    "print(df_performance)\n",
    "print('-'*30)\n",
    "\n",
    "save_path_performance = os.path.join('DPPP_daily_result', f'performance.xlsx')\n",
    "df_performance.round(4).to_excel(save_path_performance,index=False)\n",
    "\n",
    "# 修改 'net_value' 列的列名，添加 γ=gamma\n",
    "merged_net_value_df = net_value_dfs[0][['date']]  # 初始化合并的 DataFrame，只保留 'date' 列\n",
    "for net_value_df in net_value_dfs:\n",
    "    merged_net_value_df = pd.merge(merged_net_value_df, net_value_df, on='date', how='left')\n",
    "merged_net_value_df['baseline_net_value'] = df_net_value['baseline_net_value']\n",
    "merged_net_value_df = merged_net_value_df[['date', 'baseline_net_value'] + [col for col in merged_net_value_df.columns if col not in ['date', 'baseline_net_value']]]\n",
    "\n",
    "# 输出结果\n",
    "print(merged_net_value_df)\n",
    "merged_net_value_df.to_csv('DPPP_daily_result/merged_net_value_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(column)\n",
    "X = current_train[column].values[-2000:]\n",
    "\n",
    "# 将 X 转换为 torch.Tensor 类型\n",
    "X_tensor = torch.from_numpy(X).float()\n",
    "\n",
    "# 定义一个包装函数\n",
    "def model_wrapper(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = torch.from_numpy(x).float()\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        output = output.numpy()\n",
    "    return output\n",
    "\n",
    "# 创建一个 Independent masker\n",
    "masker = shap.maskers.Independent(data=X)\n",
    "\n",
    "# 使用 shap 计算特征重要性，传入包装后的模型和 masker\n",
    "explainer = shap.Explainer(model_wrapper, masker=masker)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# 计算每个特征的平均绝对 SHAP 值\n",
    "mean_abs_shap = np.mean(np.abs(shap_values.values), axis=0)\n",
    "\n",
    "# 将特征重要性与特征名称关联\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': column,\n",
    "    'Importance': mean_abs_shap\n",
    "})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 选取最大和最小的 10 个特征\n",
    "top_10 = importance_df.head(10)\n",
    "bottom_10 = importance_df.tail(10)\n",
    "\n",
    "# 合并数据\n",
    "combined = pd.concat([top_10, bottom_10])\n",
    "\n",
    "# 为最大和最小的 10 个特征设置不同颜色\n",
    "colors = ['blue'] * 10 + ['red'] * 10\n",
    "\n",
    "# 可视化特征重要性\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(combined['Feature'], combined['Importance'], color=colors)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('SHAP Importance')\n",
    "plt.title('Top 10 and Bottom 10 Feature Importance for Stock Weight Prediction (SHAP)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 添加图例\n",
    "plt.legend(handles=[plt.Rectangle((0, 0), 1, 1, color='blue'),\n",
    "                    plt.Rectangle((0, 0), 1, 1, color='red')],\n",
    "           labels=['Top 10 Important Features', 'Bottom 10 Important Features'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import random\n",
    "from scipy import stats\n",
    "plt.rcParams['font.family'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_path = r\"上证50月度因子+收益+权重数据2005-2024.csv\"\n",
    "df = pd.read_csv(file_path,parse_dates=['date'])\n",
    "df['weight'] = df['weight']/100\n",
    "column = df.columns.tolist()[7:]\n",
    "ics = {}\n",
    "for factor in column:\n",
    "    ic = df.groupby('date').apply(lambda x: x[factor].corr(x['ret_o2c_next_month']))\n",
    "    ics[factor] = ic\n",
    "\n",
    "# 将IC序列转换为DataFrame\n",
    "ic_df = pd.DataFrame(ics)\n",
    "\n",
    "# 计算IC_Mean和IC_Std\n",
    "ic_mean = ic_df.mean()\n",
    "ic_std = ic_df.std()\n",
    "\n",
    "# 计算IC_Mean/IC_Std的比值\n",
    "ic_ratio = ic_mean / ic_std\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(ic_mean, kde=True, color='skyblue')\n",
    "plt.title('Frequency Distribution of IC_Mean', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('IC_Mean', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.gca().set_facecolor('whitesmoke')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(ic_ratio, kde=True, color='salmon')\n",
    "plt.title('Frequency Distribution of IC_Mean / IC_Std', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('IC_Mean / IC_Std', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.gca().set_facecolor('whitesmoke')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
